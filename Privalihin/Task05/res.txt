         |  5  |  10 | 100 | 1K  | 10K | 100K | 1M  | 10M | 100M |
bubble   |  0  |  0  |  0  | 0.01| 0.27| 22.7 | N/A | N/A | N/A  |
insertion|  0  |  0  |  0  |  0  | 0.17| 12.57| N/A | N/A | N/A  |
merge    |  0  |  0  |  0  |  0  | 0.02| 0.05 | 0.42| 4.33| 40.91|
quick    |  0  |  0  |  0  |  0  | 0.04| 0.01 | 0.36| 4.13| 40.91|
heap     |  0  |  0  |  0  |  0  | 0.04| 0.06 | N/A | N/A | N/A  |
Выводы:
1) Большая часть времени в работе реального приложения уходила на вывод ответа (там, где GProf указывал время работы в 4 секунды,
реально проходило минимум полминуты).
2) Алгоритмы с квадратичной сложностью демонстрируют оную квадратичную сложность и работают медленно. При этом, благодаря меньшему
количеству сравнений, сортировка вставками работает примерно вдвое быстрее пузырьковой (можно еще соптимизировать, использовав
бинпоиск для поиска места вставки).
3) Чем дальше в лес, тем большее значение имеет выделение дополнительной памяти. Работающий без нее quickSort() ощутимо обгоняет
mergeSort(), а heapSort(), который в моей реализации выделяет больше всех памяти, работает настолько медленно, что я даже не
дождался конца для последних трех опытов (хотя это может быть и какая-то ошибка в реализации, не исключено).
4) Выделение памяти и ввод/вывод имеют настолько большое значение, что алгоритмы, имеющие сложность n * log(n), демонстрируют
скорее линейную зависимость от размера входных данных.
5) Для опыта использовались небольшие (длины до 100) случайно сгенерированные строки. При увеличении их размера время работы начало
бы еще больше зависеть от ввода/вывода и выделения памяти, а если бы строчки имели вид "aaaa<...>ab", "aaaa<...>ac" и.т.д, ощутимо
больше времени начало бы уходить на сравнения.
